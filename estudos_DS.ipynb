{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNBmmdxxtsJ0rIFP5AnsqyF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VivianeMatosOliveira/Estudos_Data_Science/blob/main/estudos_DS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= 'https://www.datanami.com/wp-content/uploads/2018/09/data_science_shutterstock_shutterstock_Trueffelpix.jpg'>\n",
        "\n",
        "# **Trilha de estudos** | *Data Science*\n",
        "**By** Viviane Matos"
      ],
      "metadata": {
        "id": "qfKg8PEx2VHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Etapas de um projeto de DATA SCIENCE**"
      ],
      "metadata": {
        "id": "Tt11YxI2s1eX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://miro.medium.com/max/640/1*_fR-2Yg-xaWXssnj08Zqeg.webp'>\n"
      ],
      "metadata": {
        "id": "BxFL7oTNsfXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Problema de negócio\n",
        "\n",
        "Planejamento da solução para o problema de negócio:\n",
        "\n",
        "1. Planejar como será entregue o produto final (e-mail, planiha, gráfico, etc.)\n",
        "\n",
        "2. Planejamento do processo\n",
        "\n",
        "Passos para encontrar as respostas:\n",
        "*  Coletar um conjunto de dados (onde estão os dados?)\n",
        "*  Manipular esses dados para obter as respostas de acordo com as perguntas do problema de negócio\n",
        "\n",
        "3. Planejamento da ferramenta - quais ferramentas irão auxiliar a manipulação dos dados\n",
        "*  linguagem de programação: python (qual biblioteca usar?) / R / SQL \n",
        "*  ferramentas da estatística\n",
        "*  qual IDE?\n"
      ],
      "metadata": {
        "id": "sVpk82_U_N7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1\\. **Conceitos**"
      ],
      "metadata": {
        "id": "koqGQ4lY7U2j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **1.1 Data Science** "
      ],
      "metadata": {
        "id": "SVoSPjOh761Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ciência de Dados (ou Data Science) é o termo usado \n",
        "para definir a extração de insights de dados que são \n",
        "coletados de várias fontes.\n",
        "\n",
        "Utilizando várias técnicas, incluindo modelagem \n",
        "preditiva (Machine Learning), a Ciência de Dados ajuda \n",
        "a analisar e interpretar grandes quantidades de dados.\n",
        "\n",
        "O principal objetivo da Ciência de Dados é extrair e \n",
        "interpretar os dados de forma eficaz e apresentá-los \n",
        "em uma linguagem simples para os usuários finais e \n",
        "tomadores de decisão\n",
        "\n",
        "Em essência, a Ciência de Dados envolve o uso de \n",
        "métodos automatizados (Ciência da Computação) para \n",
        "analisar (Matemática e Estatística) enormes \n",
        "quantidades de dados a fim de extrair conhecimento \n",
        "(áreas de negócio) a partir dos dados.\n",
        "\n",
        "Estes são os 5 requisitos básicos para que possamos aplicar a Ciência de Dados:\n",
        "\n",
        "1- Problema de Negócio\n",
        "\n",
        "2- Dados Históricos\n",
        "\n",
        "3- Padrão Existente nos Dados\n",
        "\n",
        "4- Capacidade Computacional Para Armazenamento e Processamento de Dados\n",
        "\n",
        "5- Profissionais Qualificado\n",
        "\n",
        "Todo projeto de Data Science \n",
        "deve começar com o objetivo, ou \n",
        "seja, as questões que precisam \n",
        "ser respondidas. \n",
        "\n",
        "Depois de formuladas as \n",
        "questões, busca-se os dados que \n",
        "ajudarão a respondê-las.\n",
        "\n",
        "**Fonte:** Data Science Academy"
      ],
      "metadata": {
        "id": "CtqGUhMq99Zp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 Dados** "
      ],
      "metadata": {
        "id": "XPzFu9M2CNMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "São um\n",
        "conjunto de valores de variáveis qualitativas ou\n",
        "quantativas sobre eventos, pessoas ou objetos. Os dados podem ser qualquer caracter, \n",
        "texto, palavras, números, imagens, som \n",
        "ou vídeo e, se não colocados em \n",
        "contexto, significam pouco ou nada para \n",
        "um ser humano.\n"
      ],
      "metadata": {
        "id": "v8aP-XtMCZw3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os dados podem ser estruturados, Semi Estuturados ou Não estruturados"
      ],
      "metadata": {
        "id": "GS-dTNct86xM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://www.salesforce.com/content/dam/blogs/br/2020/Data%20Lakes%20x%20Data%20Warehouses.jpg'>"
      ],
      "metadata": {
        "id": "5Zl4lvlF8wfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dados Estruturados**\n",
        "\n",
        "São dados formatados segundo parâmetros específicos, para organização em esquemas relacionais. Um dos principais formatos de dados estruturados são as tabelas, que os distribuem em linhas e colunas com valores pré-determinados.  \n",
        "\n",
        "Exemplos: planilhas eletrônicas e bancos de dados (arquivos do Excel, CSV, SQL, JSON, entre outros).≥÷\n",
        "\n",
        "**Dados Semiestruturados**\n",
        "\n",
        "Como o nome indica, são dados com alguma organização interna, mas que não são inteiramente estruturados.\n",
        "\n",
        "Exemplos: arquivos da web (HTML, XML, OWL, entre outros).\n",
        "\n",
        "**Dados Não Estruturados**\n",
        "\n",
        "São dados sem uma organização ou hierarquia interna clara. É a categoria mais ampla, abrangendo a maior parte dos dados na web.\n",
        "\n",
        "Exemplos: documentos de texto (arquivos do Word, PDFs), arquivos de mídia (imagem, áudio e vídeo), e-mails, mensagens de texto, dados de redes sociais, dispositivos móveis, Internet das Coisas (IoT), entre outros."
      ],
      "metadata": {
        "id": "7BdubuV49bGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.3 Big Data** "
      ],
      "metadata": {
        "id": "OWXoHqYDDlNi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Big Data é uma coleção de conjuntos de dados, grandes e complexos, \n",
        "que não podem ser processados por bancos de dados ou aplicações \n",
        "de processamento tradicionais.\n",
        "\n",
        "Podemos definir o conceito de Big Data como sendo conjuntos de dados \n",
        "extremamente amplos e que, por este motivo, necessitam de ferramentas \n",
        "especialmente preparadas para lidar com grandes volumes, velocidade e \n",
        "variedade, de forma que toda e qualquer informação disponível nos dados \n",
        "possa ser encontrada, analisada e aproveitada em tempo hábil.\n",
        "\n",
        "Big Data é definido por 4 V’s:\n",
        "\n",
        "• **Volume**\n",
        "\n",
        "• **Variedade**\n",
        "\n",
        "• **Velocidade**\n",
        "\n",
        "• **Veracidade**\n",
        "\n",
        "O Big Data pode ser composto\n",
        "por dados de diferentes fontes e\n",
        "diferentes formatos.\n",
        "\n",
        "***Big Data Analytics*** é a aplicação da Ciência de \n",
        "Dados para a análise de Big Data.\n",
        "Com Big Data Analytics o objetivo é resolver \n",
        "problemas de negócio através da análise de \n",
        "dados com alto volume, variedade e gerados em \n",
        "alta velocidade.\n",
        "\n",
        "Big Data é a matéria-prima, ou seja, dados. \n",
        "Ciência de Dados é um conjunto de técnicas para análise de dado"
      ],
      "metadata": {
        "id": "Oryxb479EXvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.4 Analitcs** "
      ],
      "metadata": {
        "id": "YyVcjIdNy1Gq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analitcs**  - perguntas aos dados - traz reflexão sobre dos dados - toda as esferas da empresa sendo direcionada pelos dados - estratégia, tática e operacional\n",
        "\n",
        "\n",
        "*   O que aconteceu?\n",
        "*   Por que aconteceu?\n",
        "*   O que acontecerá? Análise de dados históricos\n",
        "*   O que eu posso fazer?\n",
        "\n",
        "\n",
        "Ao responderem essas perguntas realiza-se as análises:\n",
        "\n",
        "**Descritiva:** coleta condições do ambiente e da operação. Perspectiva histórica - geralmente de sistemas transacionais - ERP e CRM - consultas/relatórios\n",
        "\n",
        "**Diagnóstica:** examina as causas / foca na relação de causas e consequências. Identificar padrões em grandes quantidades de dados por meio de mineração de dados/ correlacionar os indicadores e suas métricas\n",
        "\n",
        "**Preditiva:** identifica tendências futuras / detecta padrões e comportamentos / usa dados históricos e algoritmos preditivos para\n",
        "Ajudar a determinar a probabilidade do que acontecerá em seguida\n",
        "\n",
        "**Prescritiva:** traça as possíveis consequências de cada ação/determina o que deve ocorrer e como fazer / identifica medidas para melhorar os resultados ou par"
      ],
      "metadata": {
        "id": "YYeZlUTmyWw8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.5 ETL X ELT** "
      ],
      "metadata": {
        "id": "9AmxX3SM2isu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ETL: Como funciona o processo?**\n",
        "\n",
        "**Extração (E):** nesta fase, os dados são coletados de diferentes sistemas organizacionais e conduzidos a um espaço temporário (staging area), onde são convertidos em um mesmo formato para transformação.\n",
        "\n",
        "**Transformação (T):** os dados brutos são lapidados e padronizados conforme as necessidades da empresa. Ao fim desta etapa, os dados estão “limpos”, estruturados e prontos para armazenamento.\n",
        "\n",
        "**Carregamento (L):** os dados tratados são enviados a um repositório específico, onde serão armazenados em segurança e acionados para consulta interna."
      ],
      "metadata": {
        "id": "8VCMn8fX93Sa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Administração de ETL:** dados oriundos do mundo **transacional** voltados ao controle são transformados em **dimensionais**, voltados à analise\n",
        "Extração dos dados dos sistemas relacionais e carga dos dados no sistema dimensional\n",
        "Transformação - trabalhar a qualidade dos dados\n"
      ],
      "metadata": {
        "id": "3UWL-yxf2NQZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://media.striim.com/wp-content/uploads/2021/03/10234532/Infographic-Option-4-2.png'>"
      ],
      "metadata": {
        "id": "rmwNR_JTpg5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.6 DATAOPS** "
      ],
      "metadata": {
        "id": "QD4SZzir3gLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "É uma pratica de gerenciamento de dados colaborativa focada em melhorar comunicacao integracao e automacao de fluxos de dados entre produtores e consumidores de dados de uma organizacao.\n",
        "\n",
        "Visa as entregas rápidas com gerenciamento de mudancas de dados, modelos de dadis e artefatos relacionados. refere-se a trazer velocidade e agilidade ao processo de pipelines de dados, ou seja, executar da forma mais eficiente uma serie de etapas de processamento de dados, de ponta a ponta (do inicio pela aquisicao dos dados à sua entrega final)"
      ],
      "metadata": {
        "id": "0WQ3Gk-63TDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.7 Dicionário de Dados** "
      ],
      "metadata": {
        "id": "YYkbZv0F3z8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "É um conjunto de tabelas que armazena informações sobre um banco de dados (metados). O dicionário de dados fornece uma descrição do banco de dados. Nele tem a estrutura fisica, lógica e seu conteudo. é criado durante o processo de criação do banco e consiste em uma série de tabelas e views."
      ],
      "metadata": {
        "id": "Z2Dyp_OA3t8y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.8 Análise Exploratória de Dados** "
      ],
      "metadata": {
        "id": "yk314V-JfgYn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Análise exploratória de dados ([artigo](https://towardsdatascience.com/exploratory-data-analysis-8fc1cb20fd15) de referência) através das seguintes etapas:\n",
        " 1.   Exploração;\n",
        " 1.   Manipulação;\n",
        " 1.   Visualização;\n",
        " 1.   *Storytelling*."
      ],
      "metadata": {
        "id": "rD6ChVB8fbOd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2\\. **Estatística**"
      ],
      "metadata": {
        "id": "9JVNn0_paVcS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estatística é a ciência, parte da \n",
        "Matemática Aplicada, que fornece \n",
        "métodos para coletar, descrever, \n",
        "analisar, apresentar e interpretar\n",
        "dados, para a utilização dos mesmos \n",
        "na tomada de decisões.\n",
        "\n",
        "Portanto, a Estatística trabalha \n",
        "com variáveis, que podem \n",
        "assumir diferentes valores, em \n",
        "diferentes unidades\n",
        "\n",
        "A Estatística trata dados.\n",
        "\n",
        "Todo dado se refere a uma variável.\n",
        "\n",
        "**Probabilidade:** Estudo da aleatoriedade e da incerteza.\n",
        "\n",
        "**Estatítisca Descritiva:** Utiliza métodos para coleta, organização, \n",
        "apresentação, análise e síntese de dados \n",
        "obtidos de uma população ou amostra.\n",
        "\n",
        "**Estatística Inferencial:** É o processo de estimar informações \n",
        "sobre uma população a partir dos \n",
        "resultados observados em uma amostra\n",
        "\n",
        "A Estatística fornece ferramentas, \n",
        "técnicas e procedimentos que podem ser \n",
        "usados em todas as etapas de projetos \n",
        "de Ciência de Dados.\n",
        "\n"
      ],
      "metadata": {
        "id": "rTCv06SFaikk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3\\. **Machine Learning**"
      ],
      "metadata": {
        "id": "CIWtlAdMcvAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4\\. **Storytelling**"
      ],
      "metadata": {
        "id": "QtpAXNfgc4W_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5\\. **Cloud Computing**"
      ],
      "metadata": {
        "id": "H9Zz_Av5c96z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Computação em Nuvem (Cloud Computing) \n",
        "é a entrega de serviços de computação -\n",
        "incluindo servidores, armazenamento, bancos \n",
        "de dados, rede, software, análise e \n",
        "inteligência - pela Internet (“a nuvem”) para \n",
        "oferecer recursos flexíveis, inovação e \n",
        "economia de escala. "
      ],
      "metadata": {
        "id": "xA2KbufGno5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6\\. **Data Viz**"
      ],
      "metadata": {
        "id": "RRok8tsXdEEd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refere-se a técnicas usadas para comunicar insights de dados pela representação visual. Tem como objetivo principal extrair grandes conjuntos de dados em gráficos visuais para permitir a fácil compreensão de relações complexas nos dados.\n",
        "É a etapa do processo de ciência de dados que se inicia após os dados serem coletados, processados e modelados. Os dados precisam ser visualizados em busca de encontrar alguma conclusão\n"
      ],
      "metadata": {
        "id": "87qoBBjFwBHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7\\. **Sistemas de Armazenamento de Dados**"
      ],
      "metadata": {
        "id": "YbuNQt-6hpr1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Existem duas grandes categorias de armazenamento de dados de uso comum:\n",
        "\n",
        "Armazenamentos de arquivos\n",
        "bancos de dados\n",
        "\n",
        "Alguns formatos de arquivo comuns\n",
        "\n",
        "*  O formato mais comum para dados delimitados é o de valores separados por vírgula (CSV), no qual os campos são separados por vírgulas e as linhas são encerradas por um retorno de carro/nova linha\n",
        "\n",
        "*  JSON é um formato onipresente no qual um esquema de documento hierárquico é usado para definir entidades de dados (objetos) que possuem vários atributos. Cada atributo pode ser um objeto (ou uma coleção de objetos); tornando o JSON um formato flexível que é bom para dados estruturados e semiestruturados.\n",
        "\n",
        "*  XML usa tags entre colchetes angulares ( <../> ) para definir elementos e atributos\n",
        "\n",
        "*  Objeto Binário Grande (BLOB) - imagens, vídeo, áudio e documentos específicos do aplicativo.\n",
        "\n",
        "Alguns formatos de arquivo otimizados comuns que você pode ver incluem Avro , ORC e Parquet"
      ],
      "metadata": {
        "id": "IFourH-A9LA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BDr0iwhP9vq5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.1 Data Warehouse (DW)** "
      ],
      "metadata": {
        "id": "e8weuXr9h9av"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalmente, um esquema de data warehouse é baseado em tabelas de fatos que contêm valores numéricos que você deseja analisar (por exemplo, valores de vendas), com tabelas de dimensão relacionadas que representam as entidades pelas quais você deseja medi-los (por exemplo, cliente ou produto) "
      ],
      "metadata": {
        "id": "VlDFEqrBAXWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= 'https://www.fusionsol.com/wp-content/uploads/sites/2/2022/10/image-26.png'>"
      ],
      "metadata": {
        "id": "usr29yFf7Qnm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "É um sistema de armazenamento\n",
        "que conecta e harmoniza grandes quantidades de dados de\n",
        "muitas fontes diferentes.\n",
        "Seu objetivo é alimentar a inteligência de negócios (Business\n",
        "Intelligence), relatórios e análises e oferecer suporte aos\n",
        "requisitos de negócio, para que as empresas possam\n",
        "transformar seus dados em insights e tomar decisões\n",
        "inteligentes baseadas em dados.\n",
        "Os DWs armazenam dados atuais e históricos em um único\n",
        "lugar e atuam como a única fonte de informações confiáveis\n",
        "para uma organização.\n",
        "\n",
        "Os dados fluem para um DW a partir de sistemas\n",
        "transacionais (como ERP e CRM), bancos de dados e fontes\n",
        "externas, como sistemas de parceiros, dispositivos de Internet\n",
        "das Coisas (IoT), aplicativos de mídia social - geralmente em\n",
        "uma cadência regular\n",
        "\n",
        "**IMPORTANTE:** O schema deve ser definido antes do processo de\n",
        "armazenamento dos dados.\n",
        "\n",
        "Como literais “armazéns de dados”, os data warehouses reúnem dados históricos para classificação em blocos semânticos, chamados relações. Por isso, o data warehouse é um banco de dados relacional, contendo principalmente dados estruturados.\n",
        "\n",
        "Os dados do data warehouse são distribuídos em subconjuntos chamados data marts (“mercados de dados”), que agilizam a recuperação e entrega de dados para times específicos.\n",
        "\n",
        "Uma vez solicitados, os dados do data warehouse são disponibilizados em modo de leitura, conforme a demanda dos analistas de big data e BI.\n",
        "\n",
        "Os DWs modernos são projetados para lidar com dados\n",
        "estruturados e não estruturados, como vídeos, arquivos de\n",
        "imagem e dados de sensor (embora Data Lakes ainda sejam\n",
        "opções melhores para dados não estruturados).\n",
        "\n",
        "Para o DW normalmente usamos **ETL** (Extração, Transformação e\n",
        "Carga)\n",
        "\n",
        "**Não é criado para realizar controles, mas sim análises**\n",
        "\n",
        "**Características de um DW**\n",
        "\n",
        "1. Orientado por assunto: contêm informações sobre os processos de negócio da empresa\n",
        "\n",
        "2. Não volátil: permite apenas a carga de novos dados e consultas\n",
        "\n",
        "3. Variável no tempo: contém dados não atualizáveis que se referem a algum momento especifico\n",
        "\n",
        "4. Integrado: contém dados em um estado uniforme, ou seja, existe uma consistência entre nomes, unidades de medidas e etc.\n",
        "\n",
        "\n",
        "**Etapas para a construção de um DW**\n",
        "\n",
        "1. **Matriz de necessidade:** como o gestor quer visualizar os dados . Levantamento de dados com o gestor. Identificação dos indicadores\n",
        "\n",
        "2.  Construção da fonte de dados a partir da base transacional - comparar com a origem dos dados\n",
        "\n",
        "3. **Modelagem dimensional:** Informações descritivas (dimensão) / métricas dos processos de negócio (tabela fato).\n",
        "\n",
        "A modelagem multidimensional visa dar simplicidade e performance de consulta.\n",
        "\n",
        "Há duas formas de implementação do modelo dimensional:\n",
        "\n",
        "1. **star schema** (dimensões desnormalizadas, alta performance, porém com requisitos de espaço de armazenamento em disco maior do que o modelo snowflake)\n",
        "\n",
        "2. **snowflake** (dimensões normalizadas, pois dimensões se relacionam com dimensões - performance menor, porém com requisitos de espaço de armazenamento em disco menor que o modelo estrela)\n",
        "\n",
        "**Importante:** No modelo dimensional as chave artificial (sk) se liga a Tabela Fato\n"
      ],
      "metadata": {
        "id": "pL339FtXiFaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelo Star Schema**"
      ],
      "metadata": {
        "id": "_eRl-tnR0YK1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://learn.microsoft.com/en-us/power-bi/guidance/media/star-schema/star-schema-example1.png'>"
      ],
      "metadata": {
        "id": "tXZr7UOD0Ih0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelo Snowflake**"
      ],
      "metadata": {
        "id": "BHunC76l0xqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://learn.microsoft.com/en-us/power-bi/guidance/media/star-schema/snowflake-design.png'>"
      ],
      "metadata": {
        "id": "3t2fKYfC0pWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.2 Data Lake** "
      ],
      "metadata": {
        "id": "Qw8WRhEzjqyt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://www.qlik.com/us/-/media/images/global-us/site-content/data-lakes/datalakediagram022x.png?rev=6ab816bcdd244337af494e83e48855d3&h=588&w=1276&hash=801FC82DCA744FD53C16274EA1D7B138'>"
      ],
      "metadata": {
        "id": "JBvMdbFJ_a_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um Data Lake é um repositório centralizado que permite armazenar\n",
        "todos os dados estruturados e não estruturados em qualquer\n",
        "escala. Podemos armazenar os dados como estão na fonte, sem ter\n",
        "que primeiro estruturá-los e executar diferentes Dpos de análises -\n",
        "de painéis e visualizações a processamento de Big Data, análises em\n",
        "tempo real e aprendizado de máquina para orientar melhores\n",
        "decisões.\n",
        "\n",
        "Dependendo dos requisitos, uma empresa bpica exigirá um Data\n",
        "Warehouse e um Data Lake, pois eles atendem a diferentes\n",
        "necessidades e casos de uso.\n",
        "\n",
        "A estrutura dos dados ou schema (esquema) não é definida quando\n",
        "os dados são capturados. Isso significa que você pode armazenar\n",
        "todos os dados em formato bruto sem a necessidade de saber quais\n",
        "perguntas de negócio deverão ser respondidas no futuro\n",
        "\n",
        "Diferentes tipos de análises, como consultas SQL, análises de Big\n",
        "Data, pesquisa de texto, análises em tempo real e aprendizado de\n",
        "máquina, podem ser usados para descobrir insights.\n",
        "\n",
        "Os Data Lakes permitem que as empresas gerem diferentes tipos de\n",
        "percepções sobre os dados, desde relatórios sobre dados históricos\n",
        "até modelos preditivos criados com Machine Learning.\n",
        "\n",
        "O principal desafio de uma arquitetura de Data Lake é que os dados\n",
        "brutos são armazenados sem supervisão do conteúdo.\n",
        "\n",
        "Para que um Data Lake torne os dados utilizáveis, ele precisa ter mecanismos definidos para catalogar e proteger os dados. Sem esses elementos, os dados não podem ser encontrados ou confiáveis, resultando em um “Pântano de Dados” (Data Swamp). Atender às necessidades de\n",
        "públicos mais amplos exige que os Data Lakes tenham governança,\n",
        "gestão de metadados, consistência semântica e controles de acesso.\n",
        "\n",
        "Para o Data Lake normalmente usamos **ELT** (Extração, Carga e\n",
        "Transformação).\n",
        "\n",
        "Data Lake é um conceito e pode ser construído com diferentes\n",
        "tecnologias como Apache Hadoop ou Bancos de Dados NoSQLc"
      ],
      "metadata": {
        "id": "dFw3o7Ahj0Fr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.3 Data Store** "
      ],
      "metadata": {
        "id": "TGwmukjklFtQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "É um repositório para armazenar e gerenciar de forma persistente coleções de dados que \n",
        "incluem não apenas dados estruturados, mas também Dpos de armazenamento variado, como documentos, \n",
        "dados no formato de chave-valor, filas de mensagens e outros formatos de arquivo.\n",
        "\n",
        "Os tipos mais comuns de Data Stores:\n",
        "\n",
        "• Armazenamento de chave-valor (Redis, Memcached)\n",
        "\n",
        "• Motor de pesquisa de texto completo (ElasDc Search)\n",
        "\n",
        "• Fila de mensagens (Apache Kaja)\n",
        "\n",
        "• Sistema de arquivos distribuídos (Hadoop HDFS, AWS S3)\n"
      ],
      "metadata": {
        "id": "gU0EeiGVlJ3w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DWs, Data Lakes e Data Stores serão usados em conjunto criando assim \n",
        "uma grande estrutura de armazenamento de dados, um **Data Hub**"
      ],
      "metadata": {
        "id": "hiUd7xamlk9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.4 Armazenamento Pararelo** "
      ],
      "metadata": {
        "id": "WWstU0XBl4iL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O armazenamento paralelo consiste em \n",
        "distribuir o armazenamento de dados através \n",
        "de diversos servidores (computadores), o que \n",
        "permite aumentar de forma considerável a \n",
        "capacidade de armazenamento usando \n",
        "hardware de baixo custo\n",
        "\n",
        "E como gerenciamos o armazenamento \n",
        "paralelo através de diversos computadores?\n",
        "\n",
        "Precisamos de um sistema de arquivos \n",
        "distribuído. Seu computador pessoal tem um \n",
        "sistema de arquivos (NTFS, ext3, etc…), mas \n",
        "ele não foi desenvolvido para \n",
        "armazenamento distribuído\n",
        "\n",
        "Entre algumas opções, o Apache Hadoop HDFS \n",
        "(Hadoop Distributed File System) tem se mostrado \n",
        "a solução ideal para gerenciar o armazenamento \n",
        "distribuído em um cluster de computadores.\n",
        "\n",
        "O HDFS é o software responsável pela gestão do \n",
        "cluster de computadores definindo como os \n",
        "arquivos serão distribuídos através do cluster.\n",
        "\n",
        "Com o HDFS podemos construir um Data Lake que \n",
        "roda sobre um cluster de computadores e permite \n",
        "o armazenamento de grandes volumes de dados \n",
        "com hardware commodity (de baixo custo).\n",
        "Isso permitiu que o Big Data pudesse ser usado em \n",
        "larga escala!\n",
        "\n",
        "Mas como vamos processar os dados se eles \n",
        "estão agora distribuídos em diversos \n",
        "computadores?\n",
        "\n",
        "No processamento paralelo o objetivo é dividir \n",
        "uma tarefa em várias sub-tarefas e executá-las \n",
        "em paralelo.\n",
        "\n",
        "O Apache Hadoop MapReduce e o Apache \n",
        "Spark são dois frameworks para esse propósito"
      ],
      "metadata": {
        "id": "OqtPvHkQl8kn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8\\. **Linux**"
      ],
      "metadata": {
        "id": "1PUFwZbLvWAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='http://3.bp.blogspot.com/-_DnFsEzDpTk/VDm4C92YXqI/AAAAAAAAA2Q/sJbE1O2ZnIM/s1600/Principais%2Bcomandos%2Bdo%2BLinux%2Be%2Bsuas%2Bfun%C3%A7%C3%B5es.JPG'>"
      ],
      "metadata": {
        "id": "aja9ze4huyFX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9\\. **Banco de Dados**"
      ],
      "metadata": {
        "id": "H6snmMz1wRFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um banco de dados é usado para definir um sistema central no qual dados podem ser armazenados e consultados."
      ],
      "metadata": {
        "id": "Yuc3XYsyz-07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9.1 Banco de Dados Relacional** "
      ],
      "metadata": {
        "id": "nf1tXh39waxK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os bancos de dados relacionais são comumente usados para armazenar e consultar dados estruturados.\n",
        "\n",
        "Normalizado, o que, em parte, significa a eliminação de valores de dados duplicados para que, por exemplo, os detalhes de um cliente individual sejam armazenados apenas uma vez e não para cada pedido de vendas que o cliente faz.\n",
        "\n",
        "As tabelas são gerenciadas e consultadas usando SQL (linguagem SQL), que se baseia em um padrão ANSII e que, portanto, é semelhante entre vários sistemas de banco de dados.\n",
        "\n",
        "Explorar o processamento de dados transacionais\n",
        "\n",
        "Um sistema transacional registra transações que encapsulam eventos específicos que a organização deseja controlar.\n",
        "Os sistemas transacionais geralmente são de alto volume, às vezes manipulando muitos milhões de transações em um dia.\n",
        "\n",
        "Os dados que estão sendo processados têm que estar acessíveis com rapidez. O trabalho executado por sistemas transacionais é geralmente conhecido como OLTP (Processamento de Transações Online).\n",
        "\n",
        "**CRUD** - os registros de dados são criados, recuperados, atualizados e excluídos \n",
        "\n",
        "Essas operações são aplicadas de maneira transacional para garantir a integridade dos dados armazenados no banco de dados.\n",
        "\n",
        "Para fazer isso, os sistemas OLTP impõem transações compatíveis com a semântica conhecida como ACID:\n",
        "\n",
        "**Atomicidade:**cada transação é tratada como uma única unidade, que é totalmente bem-sucedida ou que falha completamente\n",
        "\n",
        "**Consistência:**as transações só podem conduzir os dados do banco de dados de um estado válido para outro estado válido\n",
        "\n",
        "**Isolamento:**as transações simultâneas não podem interferir entre si e devem resultar em um estado consistente do banco de dados\n",
        "\n",
        "**Durabilidade:**quando uma transação tiver sido confirmada, ela permanecerá confirmada."
      ],
      "metadata": {
        "id": "av8Bfbg20Ypb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9.2 Modelagem de Banco de Dados** "
      ],
      "metadata": {
        "id": "mrOOZojiO9vd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cardinalidade / Obrigatoriedade: É definido pela regra de negócio\n",
        "\n",
        "**Obrigatoriedade:**\n",
        "\n",
        "(0) - pode ou não obrigatório\n",
        "\n",
        "(1) deve ou obrigatório\n",
        "\n",
        "**Cardinalidade:**\n",
        "\n",
        " 0,n / 0,1 / 1,n / 1,1\n",
        " \n",
        " 1º valor corresponde a obrigatoriedade\n",
        " \n",
        " 2º valor a cardinalidade\n",
        "\n",
        "**Relacionamento:**\n",
        "\n",
        "0:1 / 1:1 / 1:n / 0:n\n",
        "\n",
        "A cardinalidade define o máximo de ocorrencia 1 ou n\n",
        "\n",
        "Na cardinalidade 1 o minimo é 1\n",
        "\n",
        "\n",
        "FK - é a chave primaria de uma tabela que vai até a outra tabela para fazer uma referencia entre registros\n",
        "\n",
        "Em relacionamento 1x1 a chave estrangeira fica na tabela mais fraca\n",
        "\n",
        "Em relacionamento 1xn a chave estrangeira sempre ficará na cardinalidade n\n",
        "\n",
        "Em relacionamento 1:1 a coluna que se refere a FK deve ser unique\n",
        "\n",
        "Tipos de dados:\n",
        "\n",
        "1. Para caracteres : CHAR e VARCHAR\n",
        "\n",
        "2. Para numericos : FLOAT e INT\n",
        "3. Para fotos e documentos : BLOB\n",
        "4. Para textos - TEXT\n",
        "\n",
        "\n",
        "Cada caracter = 1 byte \n",
        "\n",
        "**Varchar:** varia conforme o dado \n",
        "\n",
        "**Char:** não varia - será alocado em memoria o valor especificado - é mais performático - utilzar quando o numero de caracteres for de conhecimento\n"
      ],
      "metadata": {
        "id": "OnIk6sDSvfrv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9.3 NOSQL- Banco de Dados Não Relacional** "
      ],
      "metadata": {
        "id": "Jv7i5czMwf11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bancos NoSQL permitem maior escalabilidade no sentido horizontal por meio de sistemas distribuídos em hardware de baixo custo  e desempenho\n",
        "\n",
        "São indicados para grandes cargas de dados, aplicações com exigência de velocidade na consulta e registro em grandes volumes de dados\n",
        "\n",
        "Tipo de NoSQL\n",
        "1. Tipo chave/valor - REDIS\n",
        "2. Orientado por coluna - HBASE/CASSANDRA\n",
        "3. Orientado a documentos - também armazenados chave/valor, porém os documentos são organizados em conjunto - MOGODB\n",
        "4. Grafos - estrutura compostas por vértices ligados por arestas\n",
        "Banco de dados relacionais nãp possuem funcionalidades necessárias para atender os requisitos de big data (volume, variedade, veracidade e velocidade)\n"
      ],
      "metadata": {
        "id": "SBY2pr1MxpPg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10\\. **Comandos SQL**"
      ],
      "metadata": {
        "id": "ULN_L82M9sXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scripts de banco de dados são arquivos que contém instruções SQL, que serão utilizados para a implementação de um banco de dados\n",
        "\n",
        "O arquivo deve conter um nome que ajude na sua identificação.\n",
        "\n",
        "Exemplo: script_ddl_implantacao_nomeprojeto.sql \n"
      ],
      "metadata": {
        "id": "_oP9k1cvvXzA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Boa prática para implementação de um modelo relacional para SQL**\n",
        "\n",
        "1º criar as tabela contendo campos, tipos de dados e tamanho. Utilizando o comando create table\n",
        "\n",
        "2º criar as pk e demais constraints (exceto fk), utilizando o comando alter table\n",
        "\n",
        "3º criar as fk, utilizando o comando alter table, após todas as tabelas, respectivas fk e demais constraints */\n",
        "\n",
        "**IMPORTANTE:** Constraints evitam:\n",
        "\n",
        "1º que uma tabela seja deletada se houver pendnecias;\n",
        "\n",
        "2º dados inválidos sejam inseridos em branco;\n",
        "\n",
        "3ºgarante a integridade dos dados armazenados\n",
        "\n",
        "**Tipos de constraints (oracle):**\n",
        "\n",
        "**Not null:** conteudo da coluna não poderá ser nulo\n",
        "\n",
        "\n",
        "```SQL\n",
        "SINTAXE: <nome-da-coluna> <tipo-do-dado> not null\n",
        "```\n",
        "\n",
        "\n",
        "**Unique:** indica que não pode haver repetição no conteudo da coluna (é indicado que todos os valores não nulos devem ser excluidos\n",
        "\n",
        "\n",
        "\n",
        "```SQL\n",
        "SINTAXE: <nome-da-coluna> <tipo-do-dado> unique\n",
        "```\n",
        "\n",
        "\n",
        "**Check:** definição de um dominio. Expressa os valores possíveis para o conteudo de uma coluna\n",
        "\n",
        "\n",
        "\n",
        "```SQL\n",
        "SINTAXE: <nome-da-coluna> <tipo-do-dado> check (condição / valores possíveis)\n",
        "```\n",
        "\n",
        "**Default:** atribui um conteudo padrão a uma coluna da tabela\n",
        "\n",
        "\n",
        "\n",
        "```SQL\n",
        "SINTAXE: <nome-da-coluna> <tipo-do-dado> default (conteudo padrão)\n",
        "```\n",
        "\n",
        "\n",
        "**Primary Key:**\n",
        "Identificar um unico registro na tabela\n",
        "\n",
        "```SQL\n",
        "SINTAXE: constraint<pk_nome-da constraint> primary key (nome-coluna)\n",
        "```\n",
        "\n",
        "**Foreign key:** estabelece o relacionamento entre duas tabelas\n",
        "\n",
        "\n",
        "\n",
        "```SQL\n",
        "SINTAXE: constraint <fk-nome-da-constant> foreign key (campo que é fk na tabela destino) references <tabela-origem> (campo onde é a pk)\n",
        "```\n",
        "\n",
        "**BOA PRÁTICA:** \n",
        "1. Utilizar o comando 'ALTER TABLE' para inserir constraints\n",
        "2. Não é uma BP modificar constraints\n",
        "3. Especificar nome significativo para as constraints\n"
      ],
      "metadata": {
        "id": "qWkQogHXv0K8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sintaxe para criar estrutura de tabela definindo: colunas e relacionamento PK x FK**"
      ],
      "metadata": {
        "id": "9AyqYsjwvngp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "``` SQL\n",
        "CREATE TABLE <NOME-TABELA> (\n",
        "<NOME-COLUNA> <TIPO-DO-DADO> [NOT NULL]\n",
        "PRIMARY KEY (NOME-COLUNA-CHAVE)\n",
        "FOREIGN KEY (NOME-COLUNA-CHAVE-ESTRANGEIRA)\n",
        "REFERENCES <NOME-TABELA-PAI> (NOME-COLUNA-CHAVE-PRIMARIA)\n",
        ");\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gfECmYq8vuhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **10.1 Criar Tabela**"
      ],
      "metadata": {
        "id": "IGNHzN6hv8iR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```SQL\n",
        "CREATE TABLE <NOME-DA-TABELA> (\n",
        "  <NOME-DA-COLUNA1> <TIPO-DO-DADO> CONSTRAINT,\n",
        "  <NOME-DA-COLUNA2> <TIPO-DO-DADO> CONSTRAINT,\n",
        "  <NOME-DA-COLUNA3> <TIPO-DO-DADO> CONSTRAINT\n",
        "  );\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "nCMDzAj0wM2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **10.2 Criar PK**"
      ],
      "metadata": {
        "id": "Z7rH4wkawV76"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```SQL\n",
        "ALTER TABLE <NOME-DA-TABELA>\n",
        " ADD CONSTRAINT <PK_NOME-DA-CONSTRAINT> PRIMARY KEY (NOME-COLUNA);\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "88HwuJZLwV77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **10.3 Criar Constraint Unique**"
      ],
      "metadata": {
        "id": "I9E3zAI1wV78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```SQL\n",
        "ALTER TABLE <NOME-DA-TABELA>\n",
        " ADD CONSTRAINT <UN-NOME-DA-CONSTRAINT> UNIQUE (NOME-COLUNA);\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Pnx8ZMIlwV78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **10.4 Criar FK**"
      ],
      "metadata": {
        "id": "YC4iCKQzwV79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```SQL\n",
        "ALTER TABLE <NOME-DA-TABELA>\n",
        "  ADD CONSTRAINT <FK-NOME-DA-CONSTRAINT> FOREIGN KEY (COLUNA QUE É FK NA TABELA DESTINO)\n",
        "  REFERENCES <NOME-TABELA-ORIGEM> (COLUNA ONDE É A PK);\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "GYVKJK5Lw64o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **10.5 Exclusão de Tabelas e Constraints**"
      ],
      "metadata": {
        "id": "D-Ahxid8wvQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Na clausula CASCADE CONSTRAINT são eliminadas todas as restrições de integridade referencial que se referem a chaves primarias"
      ],
      "metadata": {
        "id": "-FsEZobtwvQp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```SQL\n",
        "DROP TABLE <NOME-DA-TABELA> CASCADE CONSTRAINTS;\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "T6ygA_RtwvQp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **10.6 Comando ALTER TABLE**"
      ],
      "metadata": {
        "id": "FBn2HuJqwvQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comando ALTER TABLE - permite alterar a estrutura de uma tabela acrescentando, alterando, retirando e alterando nomes, Formatos das colunas e a integridade referencial definidas em uma determinada tabela "
      ],
      "metadata": {
        "id": "zTx3ICdJwvQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```SQL\n",
        "ALTER TABLE <NOME-DA-TABELA>\n",
        "  DROP COLUMN <NOME-DA-COLUNA>;  -- ELIMINAR COLUNAS DE UMA TABELA\n",
        "  ADD  <NOME-DA-COLUNA> <TIPO-DO-DADO> CONSTRAINTS;   --ADD PERMITE ADICIONAR COLUNAS OU RESTRIÇÕES (CONSTRAINTS) EM UMA TABELA EXISTENTE\n",
        "  RENAME TO <NOVO-NOME-DA-TABELA>;  -- RENOMEAR A PROPRIA TABELA\n",
        "  RENAME COLUMN <NOME-COLUNA> TO <NOVO-NOME-DA-COLUNA>;  -- RENOMEAR COLUNAS\n",
        "  RENAME CONSTRAINT <NOME-DA CONSTRAINT> TO <NOVO-NOME-DA-CONSTRAINT>;  -- RENOMEAR CONSTRAINTS\n",
        "  MODIFY  <NOME-COLUNA> <TIPO-DO-DADO> CONSTRAINTS;   -- MODIFY PERMITE MODIFICAR A ESTRUTURA DAS COLUNAS, COMO TIPO DE DADO, TAMANHO OU RESTRIÇÕES\n",
        "  DROP CONSTRAINT  <NOME-DA-CONSTRAINT> CASCADE ;  -- ELIMINAR CONSTRAINT DA TABELA / CASCADE APENAS PARA ELIMINAR RESTRIÇÕES DE INTEGRIDADE REFERENCIAL QUE SE REFEREM A PK\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "EdbyXH_twvQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **10.7 Criar SEQUENCES**"
      ],
      "metadata": {
        "id": "gmfo4wp1wvQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comando DDL SEQUENCES - tem a função de gerar uma série de números inteiros. Normalmente usada para preencher uma coluna de chave primaria numérica\n",
        "\n",
        "Os números são gerados de forma automática pelo SGBD. Podem ser gerados crescentes ou decrescentes\n",
        "\n",
        "Ao utilizar sequência para preencher coluna de PK, é recomendado usar NOCACHE para evitar gaps na sequencia\n",
        "\n",
        "NOCACHE reduz o desempenho, caso as lacunas gaps não for problema, utilizar CACHE \n"
      ],
      "metadata": {
        "id": "AubdLZXKwvQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```SQL\n",
        "CREATE SEQUENCE <SQ_NOME-DA-SEQUENCIA>  -- NOME DA SEQUENCIA\n",
        "  START WITH <NUMERO_INICIO_DA SEQUENCIA>  -- INFORMAR NUMERO INTEIRO USADO PARA INICIAR A SEQUENCIA. NUMERO INICIAL PADRÃO É 1\n",
        "  INCREMENT BY <NUMERO-DE-INCREMENTO>\n",
        "  MAXVALUE <NUMERO-MÁXIMO>\n",
        "  MINVALUE <NUMERO-MINIMO>\n",
        "  CYCLE | NOCYCLE\n",
        "  CACHE  <NUMERO-CACHE  | NOCACHE\n",
        "  ORDER | NOORDER;  -- ORDER: GARANTE A ORDEM DOS NUMEROS GERADOS / NOORDER NÃO GARANTE A ORDEM DOS NUMEROS GERADOS .NOORDER É O PADRÃO\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "BeihzB6NwvQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **10.8 Inserção de Sequência - COMANDO INSERT**"
      ],
      "metadata": {
        "id": "4kOJw7JgwvQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```SQL\n",
        "INSERT INTO <NOME-DA-TABELA> (NOMES-COLUNAS)\n",
        "    VALUES (<NOME-DA-SEQUENCIA.NEXTVAL>, <VALORES-DAS-DEMAIS-COLUNAS>);\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "zpQxUx4KwvQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PARA ALTERAR SEQUENCIAS:**"
      ],
      "metadata": {
        "id": "HqMcAKFYwvQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Valor inicial de uma sequência não pode ser alterado;\n",
        "\n",
        "2. valor mínimo não pode ser maior que o valor atual da sequência;\n",
        "\n",
        "3. Valor máximo não pode ser menor que o valor atual da sequência;\n",
        "\n",
        "4. Para alterar uma sequência é necessário ser proprietário dela;\n",
        "\n",
        "5. Somente os números futuros da sequência são afetados após a alteração;\n",
        "\n",
        "6. A sequência deve ser eliminada e recriada para que seja reiniciada em um número diferente \n"
      ],
      "metadata": {
        "id": "gICiajlmwvQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```SQL\n",
        "ALTER SEQUENCE <NOME-DA-SEQUENCIA>\n",
        "INCREMENT BY <NUMERO-DE-INCREMENTO>\n",
        "  MAXVALUE <NUMERO-MÁXIMO>\n",
        "  MINVALUE <NUMERO-MINIMO>\n",
        "  CYCLE | NOCYCLE\n",
        "  CACHE  <NUMERO-CACHE>  | NOCACHE;\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "dbNMHXLJwvQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11\\. **Python para Data Science**"
      ],
      "metadata": {
        "id": "zgQ9cZEacEIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Atributos e Métodos**\n",
        "\n",
        "Objetos em Python geralmente têm tanto atributos (outros objetos\n",
        "Python armazenados “dentro” do objeto) quanto métodos (funções\n",
        "associadas a um objeto, que podem ter acesso aos seus dados\n",
        "internos).\n",
        "\n",
        "Ambos são acessados por meio da sintaxe:\n",
        "\n",
        "obj.nome_do_atributo:"
      ],
      "metadata": {
        "id": "p6pfRUDyqMdp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **11.1 Comandos IPython e Shell**"
      ],
      "metadata": {
        "id": "pMdGiBpldCwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O shell é uma maneira de interagir textualmente com seu computador"
      ],
      "metadata": {
        "id": "Qb9ovip-frJZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unix [Comandos do Shell](https://swcarpentry.github.io/shell-novice/)"
      ],
      "metadata": {
        "id": "dWFsBygqelhu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qualquer comando que funcione na linha de comando pode ser usado no IPython prefixando-o com o !caractere\n",
        "\n",
        "Você pode iniciar o shell IPython na linha de comando, exatamente\n",
        "como iniciaria o interpretador Python usual, porém isso é feito com o\n",
        "comando **ipython**"
      ],
      "metadata": {
        "id": "m3fIoZUigIMB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "sGPRErADg8kM"
      },
      "source": [
        "###**11.2 Biblioteca NumPy**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Não importa quais sejam os dados, o primeiro passo para torná-los analisáveis ​​será transformá-los em matrizes de números\n",
        "\n",
        "O armazenamento e a manipulação eficientes de matrizes numéricas são absolutamente fundamentais para o processo de fazer ciência de dados\n",
        "\n",
        "Para lidar com tais arrays numéricos é utilizado o pacote NumPy e o pacote Pandas\n",
        "\n",
        "As matrizes NumPy são como o tipo interno do Python list, mas as matrizes NumPy fornecem armazenamento e operações de dados muito mais eficientes à medida que as matrizes aumentam de tamanho.\n",
        "\n",
        "As matrizes NumPy formam o núcleo de quase todo o ecossistema de ferramentas de ciência de dados em Python\n",
        "\n",
        "Entre outros recursos, a NumPy contém:\n",
        "\n",
        "*  um objeto array multidimensional ndarray rápido e eficiente;\n",
        "\n",
        "*  funções para efetuar processamentos em todos os elementos de\n",
        "arrays ou operações matemáticas entre arrays;\n",
        "\n",
        "*  ferramentas para ler e gravar conjuntos de dados baseados em\n",
        "arrays em disco;\n",
        "\n",
        "*  operações de álgebra linear, transformadas de Fourier e geração\n",
        "de números aleatórios;\n",
        "\n",
        "*  uma API C madura para permitir que extensões Python e códigos\n",
        "C ou C++ nativos acessem as estruturas de dados e os recursos\n",
        "de processamento da NumPy.\n"
      ],
      "metadata": {
        "id": "qscxeREEiJV_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Instruções de instalação - pacote NumPy](https://numpy.org/)"
      ],
      "metadata": {
        "id": "ZUXkmmuSjKsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anaconda já tem o NumPy instalado\n",
        "\n",
        "Após a instalação é necessário importar o NumPy e verificar novamente a versão"
      ],
      "metadata": {
        "id": "uQp0CLPdjo9e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ReT-kFOTg8kO",
        "outputId": "8ef0539f-9554-4634-f838-7293a3c2d330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.21.6'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy\n",
        "numpy.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importar o NumPy usando np como um alias:"
      ],
      "metadata": {
        "id": "vspbwtnSkVqX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ooOCvP8ng8kW"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Categorias de manipulações básicas de array**\n",
        "\n",
        "*   Atributos de arrays : determinando o tamanho, forma, consumo de memória e tipos de dados de arrays\n",
        "\n",
        "*   Indexação de arrays : obtendo e definindo o valor de elementos individuais do array\n",
        "\n",
        "*   Fatiamento de arrays : obtendo e configurando subarrays menores dentro de um array maior\n",
        "\n",
        "*   Remodelagem de matrizes : alterando a forma de uma determinada matriz\n",
        "\n",
        "*   Junção e divisão de arrays : Combinando vários arrays em um e dividindo um array em muitos"
      ],
      "metadata": {
        "id": "YXwyBdsalUP7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**11.3 Biblioteca Pandas**"
      ],
      "metadata": {
        "id": "dgEUB5dOKWxa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Vários métodos e atributos úteis de dataframes, como:\n",
        "\n",
        "info()\n",
        "\n",
        "head()\n",
        "\n",
        "dtypes\n",
        "\n",
        "columns\n",
        "\n",
        "shape\n",
        "\n",
        "Criar uma Series booleana usando o método isin(..) a partir do dataframe\n",
        "Filtrar os dados de um dataframe baseado na Series booleana\n",
        "\n",
        "\n",
        "Ordenar os dados de um dataframe (métodos sort_values() e sort_index())"
      ],
      "metadata": {
        "id": "KwFCF26V9usU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "37858VsqILQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Comandos Pandas**"
      ],
      "metadata": {
        "id": "G6LR-nLDHOeX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Importar a biblioteca"
      ],
      "metadata": {
        "id": "40aRCVANIJLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "FwRNaxtuIOpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Renomear colunas do DataFrame\n"
      ],
      "metadata": {
        "id": "F8XzXm6WOi6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={'nome': 'nome_completo'}, inplace = True)  #Para que a alteração seja implementada no df é necessário adicionar o argumento **inplace = True**"
      ],
      "metadata": {
        "id": "TOaNjY9gOdNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('dados.csv', delimiter=';', encoding='iso-8859-1', usecols=['nome_completo', 'idade']) #Para nomear as colunas assim que chamar a função read_csv do pandas"
      ],
      "metadata": {
        "id": "8JBoSCNNPS6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_html('diretorio_do_arquivo') # ler arquivo em html"
      ],
      "metadata": {
        "id": "MLImQh6ZJx3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Remover linhas duplicadas"
      ],
      "metadata": {
        "id": "49ZQq7uu_WDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates()"
      ],
      "metadata": {
        "id": "67HDEOTXHbnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Ler fontes de dados diferentes"
      ],
      "metadata": {
        "id": "ywj5YpSrI2dC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv('diretorio_do_arquivo') # ler aquivo em csv"
      ],
      "metadata": {
        "id": "bxBvvIpoI6L2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_json('diretorio_do_arquivo') # ler arquivo em json"
      ],
      "metadata": {
        "id": "MNggbR6_JFkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_table('diretorio_do_arquivo') # ler arquivo em txt"
      ],
      "metadata": {
        "id": "i5ui41qDJRtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_excel('diretorio_do_arquivo') # ler arquivo em excel"
      ],
      "metadata": {
        "id": "e8K50t-AJe2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Exportar e gravar os dados do dataframe para csv"
      ],
      "metadata": {
        "id": "ay3c8Cc5KGU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('nome_do_arquivo')"
      ],
      "metadata": {
        "id": "TDew_BZIKMZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Outras Bibiotecas para análise de dados**"
      ],
      "metadata": {
        "id": "lsOfPbH3Ww4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Bibioteca 'io'"
      ],
      "metadata": {
        "id": "BTF_3lckW9aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importe todas as suas bibliotecas aqui, siga os padrões do PEP8:\n",
        "#\n",
        "# - 1º pacotes nativos do python: json, os, etc.;\n",
        "# - 2º pacotes de terceiros: pandas, seabornm etc.;\n",
        "# - 3º pacotes que você desenvolveu."
      ],
      "metadata": {
        "id": "LfN2tqvLgYUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12\\. **Engenharia de Dados**"
      ],
      "metadata": {
        "id": "IS6bLHuClIu9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= 'https://burtchworks.wpenginepowered.com/wp-content/uploads/2021/10/Data-Pipeline-graphic-crop-768x747.png'>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v6nhQyXrNtTU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **CONCEITO**: Conjunto de técnicas e procedimentos que visam tornar os dados brutos úteis e acessíveis aos consumidores de dados. Essas técnicas e procedimentos devem garantir a qualidade e integridade dos dados\n",
        "\n",
        "A engenharia de dados fornece o suporte necessário para que o processos de Ciência de dados possam ser executado"
      ],
      "metadata": {
        "id": "2osVwRXDPtmh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **ETAPAS**: \n",
        "\n",
        "*  Infraestrutura de dados\n",
        "*  Mineração de dados\n",
        "*  Processamento de Dados\n",
        "*  Aquisição de dados\n",
        "*  Modelagem de dados\n",
        "*  Gerenciamento de dados"
      ],
      "metadata": {
        "id": "3K8PkAPBQxcu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HIERARQUIA DE NECESSIDADE EM DATA SCIENCE** "
      ],
      "metadata": {
        "id": "PTKx3fX9U7jn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= 'https://i0.wp.com/efagundes.com/wp-content/uploads/2020/10/projetos-de-IA-hierarquia-de-necessidades.jpg?ssl=1'>"
      ],
      "metadata": {
        "id": "EsLtbLmCUkdI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PIPELINE DE DADOS:** è uma série de etapas de processamento de dados.É um meio de mover os dados de sua origem para um destino, como por exemplo qualquer repositório como um DW ou DL ou ainda serem usados em tempo real - real time.\n",
        "\n",
        "Ao longo do caminho os dados são tratados e otimizados para que possam ser analisados e utilizados em insight de negócios\n",
        "\n",
        "Normalmente o pipeline de dados inclui carregar os dados brutos em uma tabela de preparação ( staging area - área intermediária) para armazenamento temporário, para poder tratar os dados antes de inseri-los no destino.\n",
        "\n",
        "**Componentes do pipeline de dados**:\n",
        "\n",
        "1. Origem\n",
        "2. Processamento\n",
        "3. Destino\n",
        "\n",
        "Um pipeline de dados pode ser criados para dados em lote (Batch), dados em streaming ou ambos\n",
        "\n",
        "**Principais ferramentas para construção de pipeine**\n",
        "\n",
        "* **Para transformação dos dados:** Apache Beam (requer programação), Airbyte (não requer programação), Dataform, Apache Airflow (com python) - gratuita, Apache Kafka ( extraçãop de dados em tempo real), Apache Spark ( trabalha em ambiente distribuido), AWS Glue, Amazon Athena (usa linguagem SQL)\n",
        "\n",
        "* **Para armazenamento:** Databrikcs, DeltaLake, Apache Hadoop (armazenamento distribuido), Apache Hive, SnowFlake,GoogleBigQuery,Amazon S3, Amazon Redshift, Azure Data Factory\n",
        "\n",
        "* **Para real time analitcs:** Tableau (conectar diretamente no pipeline de dados),Amazon Kinesis, Presto (SQL)"
      ],
      "metadata": {
        "id": "as2NmwLGWhO6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= 'https://cibersistemas.pt/wp-content/uploads/2020/10/analytics-2-2048x1152.png'>"
      ],
      "metadata": {
        "id": "U5x8WWGTZH54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Processo de Engenharia de Dados**:"
      ],
      "metadata": {
        "id": "90pAluZ6vdY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  **Primeira Etapa:** extração de dados de uma mais fontes , de dados em batch ou streaming\n",
        "\n",
        "*  **Segunda Etapa:** preparação dos dados, com atividade de limpeza,transformação,enriquecimento e segurança de acesso\n",
        "\n",
        "*  **Terceira Etapa:** armazernamento dos dados no destino ou uso em tempo real\n",
        "\n",
        "Após essas etapas os dados podem ser usados para análises, gráficos, ML, IA, Dashboards, etc"
      ],
      "metadata": {
        "id": "P8MdHGA2vwvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Ciclo de vida da Engenharia de Dados**"
      ],
      "metadata": {
        "id": "gNotwIa6ySdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Fonte de dados** (origem) - em bacth ou streaming\n",
        "2. **Ingestão de dados** - através de conectores, os dados são extraidos da origem e carregados em uma plataforma de dados, para dar continuidade no processo\n",
        "3. **Transformação e enriquecimento** - limpeza e organização dos dados, colocando-os em um contexto\n",
        "4. **Carga e Uso dos Dados** - carga no destino"
      ],
      "metadata": {
        "id": "XwEW3fgYyY0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13\\. **GIT**"
      ],
      "metadata": {
        "id": "PCKw1JplMaV5"
      }
    }
  ]
}